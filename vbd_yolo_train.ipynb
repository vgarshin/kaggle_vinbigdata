{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import yaml\n",
    "import time\n",
    "import json\n",
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from tqdm.notebook import tqdm\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from IPython.display import Image, clear_output\n",
    "from collections import Counter\n",
    "from ensemble_boxes import *\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VER = 'v9'\n",
    "PARAMS = {\n",
    "    'version': VER,\n",
    "    'folds': 5,\n",
    "    'val_fold': 0,\n",
    "    'img_size': 640,\n",
    "    'yolo': 'yolov5x.pt',\n",
    "    'ytr_img_size': 640,\n",
    "    'batch_size': 6,\n",
    "    'epochs': 50,\n",
    "    'seed': 2020,\n",
    "    'sup': 'nms', # 'nms' or 'wbf'\n",
    "    'iou_th': .4,\n",
    "    'skip_box_th': .0001,\n",
    "    'comments': ''\n",
    "}\n",
    "DATA_PATH = '/u01/mrorange/vinbigdata/data'\n",
    "WRK_DIR = f'{DATA_PATH}/working/yolo_{VER}'\n",
    "LBLS_DIR = f'{DATA_PATH}/working/yolo_labels_{VER}'\n",
    "IMGS_PATH = f'{DATA_PATH}/train_{PARAMS[\"img_size\"]}'\n",
    "MDLS_PATH = f'/u01/mrorange/vinbigdata/models_{VER}'\n",
    "YOLO_DIR = f'{DATA_PATH}/working/yolov5'\n",
    "if not os.path.exists(WRK_DIR):\n",
    "    os.mkdir(WRK_DIR)\n",
    "if not os.path.exists(LBLS_DIR):\n",
    "    os.mkdir(LBLS_DIR)\n",
    "if not os.path.exists(MDLS_PATH):\n",
    "    os.mkdir(MDLS_PATH)\n",
    "with open(f'{MDLS_PATH}/params.json', 'w') as file:\n",
    "    json.dump(PARAMS, file)\n",
    "    \n",
    "def seed_all(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    #torch.manual_seed(seed)\n",
    "\n",
    "seed_all(PARAMS['seed'])\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label2color = [\n",
    "    [59,  238, 119], [222, 21,  229], [94,  49,  164], \n",
    "    [206, 221, 133], [117, 75,    3], [210, 224, 119], \n",
    "    [211, 176, 166], [63,  7,   197], [102, 65,   77], \n",
    "    [194, 134, 175], [209, 219,  50], [255, 44,   47], \n",
    "    [89,  125, 149], [110, 27,  100]\n",
    "]\n",
    "\n",
    "def plot_img(img, size=(18, 18), is_rgb=True, title='', cmap='gray'):\n",
    "    plt.figure(figsize=size)\n",
    "    plt.imshow(img, cmap=cmap)\n",
    "    plt.suptitle(title)\n",
    "    plt.show()\n",
    "\n",
    "def plot_imgs(imgs, cols=2, size=10, is_rgb=True, title='', cmap='gray', img_size=None):\n",
    "    rows = len(imgs) // cols + 1\n",
    "    fig = plt.figure(figsize=(cols * size, rows * size))\n",
    "    for i, img in enumerate(imgs):\n",
    "        if img_size is not None:\n",
    "            img = cv2.resize(img, img_size)\n",
    "        fig.add_subplot(rows, cols, i + 1)\n",
    "        plt.axis('off')\n",
    "        plt.imshow(img, cmap=cmap)\n",
    "    plt.suptitle(title)\n",
    "    plt.axis('off')\n",
    "    \n",
    "def draw_bbox(image, box, label, color, thickness=3):   \n",
    "    alpha = .1\n",
    "    alpha_box = .4\n",
    "    overlay_bbox = image.copy()\n",
    "    overlay_text = image.copy()\n",
    "    output = image.copy()\n",
    "    text_width, text_height = cv2.getTextSize(label.upper(), cv2.FONT_HERSHEY_SIMPLEX, .6, 1)[0]\n",
    "    cv2.rectangle(overlay_bbox, \n",
    "                  (box[0], box[1]), \n",
    "                  (box[2], box[3]), \n",
    "                  color, -1)\n",
    "    cv2.addWeighted(overlay_bbox, alpha, output, 1 - alpha, 0, output)\n",
    "    cv2.rectangle(overlay_text, \n",
    "                  (box[0], box[1] - 7 - text_height), \n",
    "                  (box[0] + text_width + 2, box[1]),\n",
    "                  (0, 0, 0), -1)\n",
    "    cv2.addWeighted(overlay_text, alpha_box, output, 1 - alpha_box, 0, output)\n",
    "    cv2.rectangle(output, \n",
    "                  (box[0], box[1]), \n",
    "                  (box[2], box[3]),\n",
    "                  color, thickness)\n",
    "    cv2.putText(output, \n",
    "                label.upper(), \n",
    "                (box[0], box[1]-5),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                .6, (255, 255, 255), 1, \n",
    "                cv2.LINE_AA)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(f'{DATA_PATH}/train.csv')\n",
    "train_df['img_path'] = train_df.apply(lambda row: f'{IMGS_PATH}/{row.image_id}.png', axis =1)\n",
    "print('train loaded:', train_df.shape)\n",
    "meta_df = pd.read_csv(f'{DATA_PATH}/train_meta_{PARAMS[\"img_size\"]}.csv')\n",
    "print('meta loaded:', meta_df.shape)\n",
    "train_df = pd.merge(train_df, meta_df, on='image_id')\n",
    "print('merged:', train_df.shape)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df[train_df.class_id != 14].reset_index(drop = True)\n",
    "class_ids, class_names = list(zip(*set(zip(train_df.class_id, train_df.class_name))))\n",
    "classes = list(np.array(class_names)[np.argsort(class_ids)])\n",
    "classes = list(map(lambda x: str(x), classes))\n",
    "print('classes:', classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['x_min'] = train_df.apply(lambda row: (row.x_min)/row.dim1, axis =1)\n",
    "train_df['y_min'] = train_df.apply(lambda row: (row.y_min)/row.dim0, axis =1)\n",
    "train_df['x_max'] = train_df.apply(lambda row: (row.x_max)/row.dim1, axis =1)\n",
    "train_df['y_max'] = train_df.apply(lambda row: (row.y_max)/row.dim0, axis =1)\n",
    "print(train_df.shape)\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "print(f'time elapsed: {elapsed_time // 60:.0f} min {elapsed_time % 60:.0f} sec')\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = []\n",
    "for img_id in train_df.sample(n=8)['image_id'].values:\n",
    "    boxes = train_df.loc[\n",
    "        train_df['image_id'] == img_id,\n",
    "        ['x_min', 'y_min', 'x_max', 'y_max']\n",
    "    ].values\n",
    "    boxes *= PARAMS['img_size']\n",
    "    img_labels = train_df.loc[\n",
    "        train_df['image_id'] == img_id, \n",
    "        ['class_id']\n",
    "    ].values.squeeze()\n",
    "    path = train_df.loc[\n",
    "        train_df['image_id'] == img_id,\n",
    "        ['img_path']\n",
    "    ].values[0][0]\n",
    "    img = cv2.imread(path)\n",
    "    for label_id, box in zip(img_labels, boxes):\n",
    "        color = label2color[label_id]\n",
    "        img = draw_bbox(\n",
    "            img, \n",
    "            list(np.int_(box)), \n",
    "            classes[label_id], \n",
    "            color\n",
    "        )\n",
    "    imgs.append(img)\n",
    "\n",
    "plot_imgs(imgs, size=4, cols=4, cmap=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SHOW = 500\n",
    "viz_images = []\n",
    "train_sup = []\n",
    "for i, img_id in tqdm(enumerate(train_df.image_id.unique()), total=len(train_df.image_id.unique())):\n",
    "    img_anns = train_df[train_df.image_id == img_id]\n",
    "    if (i % SHOW == 0):\n",
    "        boxes_viz = img_anns[['x_min', 'y_min', 'x_max', 'y_max']].to_numpy() * PARAMS['img_size']\n",
    "        boxes_viz = boxes_viz.tolist() \n",
    "        labels_viz = img_anns['class_id'].to_numpy().tolist()\n",
    "        path = img_anns['img_path'].values[0]\n",
    "        img  = cv2.imread(path)\n",
    "        img_ = img.copy()\n",
    "        for box, label in zip(boxes_viz, labels_viz):\n",
    "            color = label2color[int(label)]\n",
    "            img_ = draw_bbox(img_, list(np.int_(box)), classes[label], color)\n",
    "        viz_images.append(img_)\n",
    "    boxes_list = []\n",
    "    scores_list = []\n",
    "    labels_list = []\n",
    "    weights = []\n",
    "    boxes_img = []\n",
    "    labels_img = []\n",
    "    cls_ids = img_anns['class_id'].unique().tolist()\n",
    "    count_dict = Counter(img_anns['class_id'].tolist())\n",
    "    for cid in cls_ids:\n",
    "        if count_dict[cid] == 1:\n",
    "            labels_img.append(cid)\n",
    "            boxes_img.append(\n",
    "                img_anns[\n",
    "                    img_anns.class_id == cid\n",
    "                ][\n",
    "                    ['x_min', 'y_min', 'x_max', 'y_max']\n",
    "                ].to_numpy().squeeze().tolist()\n",
    "            )\n",
    "        else:\n",
    "            cls_list =img_anns[img_anns.class_id == cid]['class_id'].tolist()\n",
    "            labels_list.append(cls_list)\n",
    "            bbox = img_anns[\n",
    "                img_anns.class_id == cid\n",
    "            ][\n",
    "                ['x_min', 'y_min', 'x_max', 'y_max']\n",
    "            ].to_numpy()\n",
    "            boxes_list.append(bbox.tolist())\n",
    "            scores_list.append(np.ones(len(cls_list)).tolist())\n",
    "            weights.append(1)\n",
    "    if PARAMS['sup'] == 'nms':\n",
    "        try:\n",
    "            boxes, scores, box_labels = nms(\n",
    "                boxes=boxes_list, \n",
    "                scores=scores_list, \n",
    "                labels=labels_list, \n",
    "                weights=weights,\n",
    "                iou_thr=PARAMS['iou_th']\n",
    "            )\n",
    "        except:\n",
    "            boxes, scores, box_labels = weighted_boxes_fusion(\n",
    "                boxes_list=boxes_list, \n",
    "                scores_list=scores_list,\n",
    "                labels_list=labels_list, \n",
    "                weights=weights,\n",
    "                iou_thr=PARAMS['iou_th'],\n",
    "                skip_box_thr=PARAMS['skip_box_th']\n",
    "            )\n",
    "    elif PARAMS['sup'] == 'wbf':\n",
    "        boxes, scores, box_labels = weighted_boxes_fusion(\n",
    "            boxes_list=boxes_list, \n",
    "            scores_list=scores_list,\n",
    "            labels_list=labels_list, \n",
    "            weights=weights,\n",
    "            iou_thr=PARAMS['iou_th'],\n",
    "            skip_box_thr=PARAMS['skip_box_th']\n",
    "        )\n",
    "    else:\n",
    "        raise AttributeError('wrong supression param')\n",
    "    boxes = boxes.tolist()\n",
    "    box_labels = box_labels.astype(int).tolist()\n",
    "    boxes.extend(boxes_img)\n",
    "    box_labels.extend(labels_img)\n",
    "    for box, label in zip(boxes, box_labels):\n",
    "        x_min, y_min, x_max, y_max = (box[0], box[1], box[2], box[3])\n",
    "        train_sup.append(dict(\n",
    "            image_id=img_id,\n",
    "            class_name=classes[label],\n",
    "            class_id=int(label),\n",
    "            x_min=x_min,\n",
    "            y_min=y_min,\n",
    "            x_max=x_max,\n",
    "            y_max=y_max,\n",
    "            img_path=img_anns['img_path'].values[0],\n",
    "            dim0=img_anns['dim0'].values[0],\n",
    "            dim1=img_anns['dim1'].values[0]\n",
    "        ))\n",
    "    if (i % SHOW == 0):\n",
    "        img__ = img.copy()\n",
    "        boxes = np.array(boxes) * PARAMS['img_size']\n",
    "        boxes = boxes.tolist() \n",
    "        for box, label in zip(boxes, box_labels):    \n",
    "            color = label2color[int(label)]\n",
    "            img__ = draw_bbox(img__, list(np.int_(box)), classes[label], color)\n",
    "        viz_images.append(img__)\n",
    "\n",
    "plot_imgs(viz_images, size=6, cols=2, cmap=None)\n",
    "plt.figtext(.3, .9, 'Original Bboxes', va='top', ha='center', size=12)\n",
    "plt.figtext(.75, .9, 'WBF', va='top', ha='center', size=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_df.shape)\n",
    "train_df = pd.DataFrame(train_sup)\n",
    "print(train_df.shape)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['x_mid'] = train_df.apply(lambda row: (row.x_max+row.x_min)/2, axis =1)\n",
    "train_df['y_mid'] = train_df.apply(lambda row: (row.y_max+row.y_min)/2, axis =1)\n",
    "train_df['w'] = train_df.apply(lambda row: (row.x_max-row.x_min), axis =1)\n",
    "train_df['h'] = train_df.apply(lambda row: (row.y_max-row.y_min), axis =1)\n",
    "train_df['area'] = train_df['w'] * train_df['h']\n",
    "print(train_df.shape)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for img_id in tqdm(train_df.image_id.unique().tolist()):\n",
    "    temp_df = train_df.loc[train_df.image_id == img_id]\n",
    "    for _, row in temp_df.iterrows():\n",
    "        with open(f'{LBLS_DIR}/{img_id}.txt', 'a') as file:\n",
    "            if row.class_id == 14:\n",
    "                line = ''\n",
    "            else:\n",
    "                line = ' '.join([str(x) for x in [\n",
    "                    row.class_id, row.x_mid, row.y_mid, row.w, row.h\n",
    "                ]]) + '\\n'\n",
    "            file.write(line)\n",
    "            \n",
    "elapsed_time = time.time() - start_time\n",
    "print(f'time elapsed: {elapsed_time // 60:.0f} min {elapsed_time % 60:.0f} sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['x_min', 'y_min', 'x_max', 'y_max', 'x_mid', 'y_mid', 'w', 'h', 'area']\n",
    "X = train_df[features]\n",
    "y = train_df['class_id']\n",
    "print('X:', X.shape, '| y:', y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gkf  = GroupKFold(n_splits=PARAMS['folds'])\n",
    "train_df['fold'] = -1\n",
    "for fold, (train_idx, val_idx) in enumerate(gkf.split(train_df, groups=train_df.image_id.tolist())):\n",
    "    train_df.loc[val_idx, 'fold'] = fold\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_files = []\n",
    "val_files = []\n",
    "val_files += list(train_df[train_df.fold == PARAMS['val_fold']].img_path.unique())\n",
    "train_files += list(train_df[train_df.fold != PARAMS['val_fold']].img_path.unique())\n",
    "len(train_files), len(val_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(f'{WRK_DIR}/labels/train', exist_ok=True)\n",
    "os.makedirs(f'{WRK_DIR}/labels/val', exist_ok=True)\n",
    "os.makedirs(f'{WRK_DIR}/images/train', exist_ok=True)\n",
    "os.makedirs(f'{WRK_DIR}/images/val', exist_ok=True)\n",
    "for file in tqdm(train_files, desc='train'):\n",
    "    shutil.copy(file, f'{WRK_DIR}/images/train')\n",
    "    filename = file.split('/')[-1].split('.')[0]\n",
    "    shutil.copy(os.path.join(LBLS_DIR, filename + '.txt'), f'{WRK_DIR}/labels/train')\n",
    "for file in tqdm(val_files, desc='val'):\n",
    "    shutil.copy(file, f'{WRK_DIR}/images/val')\n",
    "    filename = file.split('/')[-1].split('.')[0]\n",
    "    shutil.copy(os.path.join(LBLS_DIR, filename + '.txt'), f'{WRK_DIR}/labels/val')\n",
    "    \n",
    "elapsed_time = time.time() - start_time\n",
    "print(f'time elapsed: {elapsed_time // 60:.0f} min {elapsed_time % 60:.0f} sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{WRK_DIR}/train.txt', 'w') as file:\n",
    "    for path in glob(f'{WRK_DIR}/images/train/*'):\n",
    "        file.write(path + '\\n')\n",
    "with open(f'{WRK_DIR}/val.txt', 'w') as file:\n",
    "    for path in glob(f'{WRK_DIR}/images/val/*'):\n",
    "        file.write(path + '\\n')\n",
    "data = dict(\n",
    "    train =  f'{WRK_DIR}/train.txt',\n",
    "    val   =  f'{WRK_DIR}/val.txt',\n",
    "    nc    = len(classes),\n",
    "    names = classes\n",
    ")\n",
    "with open(f'{WRK_DIR}/vinbigdata.yaml', 'w') as file:\n",
    "    yaml.dump(data, file, default_flow_style=False)\n",
    "file = open(f'{WRK_DIR}/vinbigdata.yaml', 'r')\n",
    "print('YAML file:')\n",
    "print(file.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(YOLO_DIR)\n",
    "print(\n",
    "    f'using torch: {torch.__version__}',\n",
    "    f'\\ndevice: {torch.cuda.get_device_properties(0) if torch.cuda.is_available() else \"CPU\"}'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytr_img_size = PARAMS['ytr_img_size']\n",
    "ytr_batch = PARAMS['batch_size']\n",
    "ytr_epochs = PARAMS['epochs']\n",
    "ytr_data = f'../yolo_{PARAMS[\"version\"]}/vinbigdata.yaml'\n",
    "ytr_yolo = PARAMS['yolo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!/opt/anaconda3/envs/orange/bin/python train.py \\\n",
    "--img $ytr_img_size \\\n",
    "--batch $ytr_batch \\\n",
    "--epochs $ytr_epochs \\\n",
    "--data $ytr_data \\\n",
    "--weights $ytr_yolo \\\n",
    "--cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elapsed_time = time.time() - start_time\n",
    "print(f'time elapsed: {elapsed_time // 60:.0f} min {elapsed_time % 60:.0f} sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -la $YOLO_DIR/runs/train/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "img = mpimg.imread(f'{YOLO_DIR}/runs/train/exp8/results.png')\n",
    "plt.figure(figsize=(16, 8))\n",
    "plt.axis('off')\n",
    "imgplot = plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "VER = 'v1'\n",
    "MDLS_PATH = f'/u01/mrorange/vinbigdata/models_{VER}'\n",
    "DATA_PATH = '/u01/mrorange/vinbigdata/data'\n",
    "YOLO_DIR = f'{DATA_PATH}/working/yolov5'\n",
    "\"\"\"\n",
    "!cp $YOLO_DIR/runs/train/exp8/weights/best.pt $MDLS_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Orange Python 3",
   "language": "python",
   "name": "orange"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
